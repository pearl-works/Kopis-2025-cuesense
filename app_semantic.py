# app_semantic.py â€” ê³µì—°ì¶”ì²œ ì±—ë´‡ 
# -----------------------------------------------------------
# 2025ë…„ KOPIS ê³µëª¨ì „ ì„œë¹„ìŠ¤ê°œë°œë¶€ë¬¸
# ê°€ë³´ìKU ì „ì¬í˜„, ì„œì§„ì£¼
# - Cuesense
# -----------------------------------------------------------

import os
import re
import math
import random
import datetime as dt
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Tuple
import base64
from pathlib import Path

import pandas as pd
import numpy as np
import pytz
import streamlit as st
from dotenv import load_dotenv
from html import escape as html_escape

from google.cloud import bigquery
from google.oauth2 import service_account
from rank_bm25 import BM25Okapi

from openai import OpenAI

# --------------------------
# 0) í™˜ê²½ì„¤ì •
# --------------------------
load_dotenv()

# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
# PROJECT_ID = os.getenv("PROJECT_ID")
# SERVICE_ACCOUNT_FILE = os.getenv("SERVICE_ACCOUNT_FILE")

#Secrets ì½ê¸°
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "").strip()
PROJECT_ID = st.secrets.get("PROJECT_ID", "").strip()
GCP_SA_INFO = st.secrets.get("gcp_service_account", None)


assert OPENAI_API_KEY.strip(), "í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”."
if not PROJECT_ID:
    raise RuntimeError("PROJECT_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš” (.env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ í™•ì¸).")

openai_client = OpenAI(api_key=OPENAI_API_KEY)

# def get_bq_client(project_id: Optional[str] = None,
#                   service_account_file: Optional[str] = None) -> bigquery.Client:
#     if service_account_file:
#         creds = service_account.Credentials.from_service_account_file(service_account_file)
#         return bigquery.Client(project=project_id or creds.project_id, credentials=creds)
#     return bigquery.Client(project=project_id)

# bq_client = get_bq_client(PROJECT_ID, SERVICE_ACCOUNT_FILE)

def get_bq_client(project_id: str, sa_info: dict) -> bigquery.Client:
    if not sa_info:
        st.error("gcp_service_accountê°€ Secretsì— ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    creds = service_account.Credentials.from_service_account_info(sa_info)
    return bigquery.Client(project=project_id or sa_info.get("project_id"), credentials=creds)

bq_client = get_bq_client(PROJECT_ID, GCP_SA_INFO)

KST = pytz.timezone("Asia/Seoul")
TODAY = dt.datetime.now(KST)

# st.set_page_config(page_title="CueSence íì„¼ìŠ¤", page_icon="ğŸ­", layout="wide")
with open("assets/cuesence_favicon.png", "rb") as f:
    st.set_page_config(page_title="CueSence íì„¼ìŠ¤", page_icon=f.read(), layout="wide")


# --------------------------
# ê³µí†µ ìœ í‹¸
# --------------------------
def fn_query(sql: str) -> pd.DataFrame:
    return bq_client.query(sql).result().to_dataframe()

def tok(s: str) -> List[str]:
    return re.findall(r"[ã„±-ã…ê°€-í£A-Za-z0-9]+", (s or ""))

def is_gpt5(model: str) -> bool:
    return model.lower().startswith("gpt-5-mini")

def chat_complete(model: str, messages: list, temperature: Optional[float] = None, **kwargs):
    payload = {"model": model, "messages": messages}
    if (temperature is not None) and (not is_gpt5(model)):
        payload["temperature"] = float(temperature)
    payload.update(kwargs or {})
    return openai_client.chat.completions.create(**payload)

# --------------------------
# 1) ë§ˆìŠ¤í„° ë°ì´í„°
# --------------------------
@st.cache_data(show_spinner=False)
def load_master_lists():
    try:
        df_genres = fn_query("SELECT genre_name FROM pg_snapshot.dm_perform_genre")
        df_cities = fn_query("SELECT REPLACE(region_name,' ','') AS region_name FROM pg_snapshot.dm_facility_region")
        df_venues = fn_query("SELECT REPLACE(facility_name,' ','') AS facility_name FROM pg_snapshot.dm_facility_name")
        return df_genres["genre_name"].tolist(), df_cities["region_name"].tolist(), df_venues["facility_name"].tolist()
    except Exception:
        # ë§ˆìŠ¤í„° í…Œì´ë¸” ì—†ìœ¼ë©´ ë¹ˆê°’ìœ¼ë¡œ
        return [], [], []

GENRES, CITIES, VENUES = load_master_lists()

# === ì£¼ì†Œ ê°€ì œí‹°ì–´(ì„œë¸Œë¡œì¼€ì´ì…˜ í›„ë³´) ë§Œë“¤ê¸° ===
_GEO_SUFFIX = r"(êµ¬|êµ°|ë™|ë¡œ|ê¸¸|ì—­|ê°€|ì|ë©´|ë¦¬)$"
_SPECIAL_NAMES = r"(ëŒ€í•™ë¡œ|í™ëŒ€|ì„±ìˆ˜|ì ì‹¤|ì••êµ¬ì •|ì²­ë‹´|ê´‘í™”ë¬¸|ì—¬ì˜ë„|ìƒì•”|ê°•ë‚¨|ì„œì´ˆ|ì¢…ë¡œ|ëª…ë™|ì´íƒœì›|í•œë‚¨|ì‹ ì´Œ|í•©ì •|ì™•ì‹­ë¦¬|ê±´ëŒ€|ê±´ëŒ€ì…êµ¬|ì ì›|ìš©ì‚°|ë§ˆí¬|ìƒì•”|ì„±ìˆ˜|ì„ ë¦‰|ì‚¼ì„±|ì—­ì‚¼|ì‚¬ë‹¹|êµëŒ€|ë…¸ì›|ìˆ˜ìœ |ìƒë´‰|ì¤‘ë‘|êµ¬ë¡œ|ì‹ ë„ë¦¼|ëª©ë™|ë§ì›|í•©ì •|ì„±ë¶|ë™ëŒ€ë¬¸|ì„ì§€ë¡œ|ì¶©ë¬´ë¡œ|ì‹ ì‚¬)"

def build_address_gazetteer(df: pd.DataFrame, max_len:int=6) -> List[str]:
    gaz = set()
    if "address" not in df.columns or df.empty:
        return []
    for addr in df["address"].dropna().astype(str):
        for tok in re.split(r"[ ,/()\-Â·]+", addr):
            tok = tok.strip()
            if not tok or len(tok) < 2: 
                continue
            if re.search(_GEO_SUFFIX, tok) or re.search(_SPECIAL_NAMES, tok):
                if tok not in {"ëŒ€í•œë¯¼êµ­", "ì„œìš¸íŠ¹ë³„ì‹œ", "ì„œìš¸ì‹œ"}:
                    gaz.add(tok.replace("ì„œìš¸íŠ¹ë³„ì‹œ","ì„œìš¸").replace("ì„œìš¸ì‹œ","ì„œìš¸"))
    gaz = {g for g in gaz if 2 <= len(g) <= max_len}
    # ë„ˆë¬´ ë§ì€ ê²½ìš° ìƒìœ„ Në§Œ ì‚¬ìš©(ê¸¸ì´ ê¸´ ê³ ìœ ëª… ìš°ì„ )
    return sorted(gaz, key=lambda x: (-len(x), x))[:600]  # LLM í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë³´í˜¸


def extract_sublocs_llm(query: str, gazetteer: List[str], top_k:int=6) -> List[str]:
    """
    ì§ˆì˜ë¬¸ê³¼ ì£¼ì†Œ ê°€ì œí‹°ì–´ë¥¼ ì£¼ë©´, LLMì´ ì§ˆì˜ì— "ê°•í•˜ê²Œ í•¨ì˜"ëœ ì§€ëª…(ê°•ë‚¨/ëŒ€í•™ë¡œ/ì„±ìˆ˜ ë“±)ë§Œ ì¶”ë ¤ì„œ ë°˜í™˜.
    - ë°˜í™˜ í˜•ì‹: JSON array of strings (ì˜ˆ: ["ê°•ë‚¨","ëŒ€í•™ë¡œ"])
    - gazetteer ë°”ê¹¥ ë‹¨ì–´ëŠ” ë²„ë¦¼ â†’ ê³¼ì í•©/í™˜ê° ë°©ì§€
    """
    if not query or not gazetteer:
        return []
    sys = (
        "ë„ˆëŠ” ê³µì—° ê²€ìƒ‰ ë³´ì¡°ìë‹¤. ì‚¬ìš©ìì˜ ë¬¸ì¥ì„ ì½ê³ , ë¬¸ì¥ ì•ˆì—ì„œ ì•”ì‹œë˜ëŠ” "
        "ì„¸ë¶€ ì§€ì—­ í‚¤ì›Œë“œ(ì˜ˆ: ê°•ë‚¨, ëŒ€í•™ë¡œ, ì„±ìˆ˜, í™ëŒ€ ë“±)ë§Œ 'ê°€ì œí‹°ì–´ ëª©ë¡'ì—ì„œ ê³¨ë¼ JSON ë°°ì—´ë¡œë§Œ ë°˜í™˜í•´ë¼. "
        "ê°€ì œí‹°ì–´ì— ì—†ëŠ” ë‹¨ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆë¼. ì¼ë°˜ ë‹¨ì–´(ì˜ˆ: ì´ë²ˆ, ì¶”ì²œí•´ì¤˜, ë°”ì´ì˜¬ë¦°)ëŠ” í¬í•¨ ê¸ˆì§€. "
        "ìµœëŒ€ 6ê°œ. ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ í•˜ë‚˜ë§Œ."
    )
    gaz_str = " / ".join(gazetteer)
    usr = (
        f"ì§ˆë¬¸: {query}\n\n"
        f"[ê°€ì œí‹°ì–´(í›„ë³´ ì§€ëª…)]\n{gaz_str}\n\n"
        "ì¶œë ¥ ì˜ˆì‹œ: [\"ê°•ë‚¨\",\"ëŒ€í•™ë¡œ\"]"
    )
    try:
        resp = chat_complete(
            CHAT_MODEL,
            [{"role":"system","content":sys},{"role":"user","content":usr}],
            temperature=0.0,
            response_format={"type": "json_object"} if is_gpt5(CHAT_MODEL) else None
        )
        txt = resp.choices[0].message.content.strip()
        # gpt-5-miniê°€ ì˜¤ë¸Œì íŠ¸ë¡œ ì¤„ ìˆ˜ ìˆì–´ í›„ì²˜ë¦¬(ë°°ì—´ë§Œ ë‚¨ê¸°ê¸°)
        try:
            import json
            obj = json.loads(txt)
            if isinstance(obj, list):
                arr = obj
            elif isinstance(obj, dict):
                # {"sublocs":[...]} ë˜ëŠ” {"result":[...]} ë¥˜ ëŒ€ì‘
                arr = obj.get("sublocs") or obj.get("result") or obj.get("locations") or []
            else:
                arr = []
            # gazetteer êµì§‘í•© + ê¸¸ì´ ì œí•œ
            arr = [s for s in arr if isinstance(s, str)]
        except Exception:
            # í˜¹ì‹œ ë°°ì—´ ë¬¸ìì—´ë¡œ ë°”ë¡œ ì˜¨ ê²½ìš°
            m = re.search(r"\[.*\]", txt, re.S)
            import json
            arr = json.loads(m.group(0)) if m else []
        # ì•ˆì „í•„í„°: ê°€ì œí‹°ì–´ ë°– ë‹¨ì–´ ì œê±° + ì¤‘ë³µ ì œê±° + ìƒí•œ
        sset = []
        gset = set(gazetteer)
        for s in arr:
            s = s.strip()
            if s in gset and s not in sset and 2 <= len(s) <= 10:
                sset.append(s)
            if len(sset) >= top_k:
                break
        return sset
    except Exception:
        return []


# --------------------------
# 2) ì¿¼ë¦¬ íŒŒì„œ (ê¸°ê°„/ì§€ì—­/ì¥ë¥´/ì¥ì†Œ/ì˜ˆì‚°/ë™ë°˜ì)
# --------------------------
@dataclass
class QueryFilters:
    start_date: dt.datetime
    end_date: dt.datetime
    city: Optional[str]
    genre: Optional[str]
    venue: Optional[str]
    max_price: Optional[int]
    with_companion: Optional[str]
    sublocs: Optional[List[str]] = None

def to_kst_midnight(ts: dt.datetime) -> dt.datetime:
    if getattr(ts, "tzinfo", None) is None:
        return KST.localize(ts.replace(hour=0,minute=0,second=0,microsecond=0))
    return ts.astimezone(KST).replace(hour=0,minute=0,second=0,microsecond=0)

def parse_user_query(q: str, base: dt.datetime, subloc_gaz: Optional[List[str]] = None) -> QueryFilters:
    q = (q or "").strip()
    base = to_kst_midnight(base)

    # ê¸°ë³¸: ì•ìœ¼ë¡œ 30ì¼
    start = base
    end   = start + dt.timedelta(days=30)

    q_norm = q.replace(" ", "")

    # === ê¸°ê°„ íŒŒì‹± (ìƒëµ: ê¸°ì¡´ ê·¸ëŒ€ë¡œ) ===
    if "ì´ë²ˆì£¼" in q_norm and "ì£¼ë§" not in q_norm and "ë‹¤ìŒì£¼" not in q_norm:
        week_start = start - dt.timedelta(days=start.weekday())
        start = week_start
        end   = week_start + dt.timedelta(days=7)
    if "ì´ë²ˆì£¼ë§" in q_norm or "ì´ë²ˆ ì£¼ë§" in q:
        weekday = start.weekday()
        start = start + dt.timedelta(days=(5 - weekday) % 7)
        end   = start + dt.timedelta(days=2)
    if "ë‹¤ìŒì£¼" in q_norm:
        weekday = start.weekday()
        start = start + dt.timedelta(days=(7 - weekday))
        end   = start + dt.timedelta(days=7)
    if "ì˜¤ëŠ˜" in q or "ê¸ˆì¼" in q:
        end = start + dt.timedelta(days=1)

    genre = next((g for g in GENRES  if g and g in q), None)
    city  = next((c for c in CITIES  if c and c in q), None)
    venue = next((v for v in VENUES  if v and v in q), None)

    max_price = 50000 if any(k in q for k in ["ì €ë ´","ê°€ì„±ë¹„","5ë§Œ","5ë§Œì›","50,000","50000"]) else None
    companion = "ì»¤í”Œ" if any(k in q for k in ["ì—¬ìì¹œêµ¬","ë‚¨ìì¹œêµ¬","ì»¤í”Œ","ë°ì´íŠ¸"]) else \
                "ê°€ì¡±" if any(k in q for k in ["ì•„ì´","ê°€ì¡±","ë¶€ëª¨ë‹˜"]) else \
                "ì¹œêµ¬" if any(k in q for k in ["ì¹œêµ¬","ë™ë£Œ"]) else None

    sublocs = extract_sublocs_llm(q, subloc_gaz or []) if subloc_gaz else None

    return QueryFilters(start, end, city, genre, venue, max_price, companion, sublocs)


def detect_intent(q: str) -> str:
    if not q: 
        return "unknown"
    qs = q.strip().lower()
    # ì´ë¦„ ì§ˆë¬¸
    if any(k in qs for k in ["ì´ë¦„", "who are you", "what is your name", "ë„ˆ ì´ë¦„", 'ì•ˆë…•']):
        return "ask_name"
    # ê³µì—° ì¶”ì²œ/ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ
    rec_kw = ["ì¶”ì²œ", "ì°¾ì•„ì¤˜", "ê³µì—°", "í˜ìŠ¤í‹°ë²Œ", "í´ë˜ì‹", "ì—°ê·¹", "ë®¤ì§€ì»¬", "ì½˜ì„œíŠ¸", "ì˜¤í˜ë¼", "ì¬ì¦ˆ", "ì•Œë ¤ì¤˜"]
    if any(k in q for k in rec_kw):
        return "recommend"
    return "other"


# --------------------------
# 3) SHOW ë¡œë“œ 
# --------------------------
@st.cache_data(show_spinner=True)

def load_show_candidates(day_setting) -> pd.DataFrame:
    sql = (f"""
            WITH clean AS (
            SELECT
                CAST(performance_code AS STRING)                   AS performance_code,
                CAST(performance_name AS STRING)                   AS performance_name,
                CAST(venue_code AS STRING)                         AS venue_code,
                CAST(venue_name AS STRING)                         AS venue_name,
                CAST(region_name AS STRING)                        AS region_name,
                CAST(address AS STRING)                        	   AS address,
                CAST(genre_name AS STRING)                         AS genre_name,
                CAST(subgenre_name AS STRING)                      AS subgenre_name,
                CAST(production_company_name AS STRING)            AS production_company_name,
                CAST(cast_info AS STRING)                          AS cast_info,
                PARSE_TIMESTAMP('%Y-%m-%d %H:%M', performance_ts, 'Asia/Seoul')    AS performance_ts,
                PARSE_TIMESTAMP('%Y-%m-%d %H:%M', booking_cancel_ts, 'Asia/Seoul') AS booking_cancel_ts,
                cast(replace(seats_for_sale, 'ì„','') AS int) AS seats_for_sale ,
                CAST(CAST(unit_price AS NUMERIC) AS INT64)                  AS unit_price,
                CAST(booking_cancel_type AS STRING)                AS booking_cancel_type,
                CAST(CAST(booking_cancel_qty AS NUMERIC) AS INT64) AS booking_cancel_qty
            FROM pg_snapshot.dw_kopis_row 
            ),
            base AS (
            -- "ë¯¸ë˜ íšŒì°¨" ëª©ë¡ (ì¤‘ë³µ ì œê±°)
            SELECT
                performance_code,
                ANY_VALUE(performance_name)           AS performance_name,
                ANY_VALUE(venue_code)                 AS venue_code,
                ANY_VALUE(venue_name)                 AS venue_name,
                ANY_VALUE(region_name)                AS region_name,
                ANY_VALUE(address)                	  AS address,
                ANY_VALUE(genre_name)                 AS genre_name,
                ANY_VALUE(subgenre_name)              AS subgenre_name,
                ANY_VALUE(production_company_name)    AS production_company_name,
                ANY_VALUE(cast_info)                  AS cast_info,
                performance_ts,
                ANY_VALUE(seats_for_sale)             AS seats_for_sale,
                ANY_VALUE(unit_price)                 AS unit_price
            FROM clean
            WHERE performance_ts >= CAST('{day_setting}' AS TIMESTAMP)
            GROUP BY performance_code, performance_ts
            ),
            recent_30 AS (
            -- ìµœê·¼ 30ì¼ ìˆœíŒë§¤ëŸ‰(ì˜ˆë§¤-ì·¨ì†Œ), ê³µì—°ì½”ë“œ ë‹¨ìœ„
            SELECT
                performance_code,
                SUM(CASE WHEN booking_cancel_type = '2'
                        THEN -COALESCE(booking_cancel_qty,0)
                        ELSE  COALESCE(booking_cancel_qty,0)
                    END) AS net_qty_30d
            FROM clean
            WHERE booking_cancel_ts >= TIMESTAMP_SUB(CAST('{day_setting}' AS TIMESTAMP), INTERVAL 30 DAY)
            GROUP BY performance_code
            ),
            genre_minmax AS (
            -- ì¥ë¥´ë³„ min/maxë¡œ ì •ê·œí™” ì¤€ë¹„
            SELECT
                c.performance_code,
                c.genre_name,
                MIN(r.net_qty_30d) OVER (PARTITION BY c.genre_name) AS min_g,
                MAX(r.net_qty_30d) OVER (PARTITION BY c.genre_name) AS max_g,
                r.net_qty_30d
            FROM (SELECT DISTINCT performance_code, genre_name FROM clean) c
            LEFT JOIN recent_30 r USING (performance_code)
            ),
            popularity_scaled AS (
            -- 0~1 ìŠ¤ì¼€ì¼ì˜ popularity
            SELECT
                performance_code,
                CASE
                WHEN max_g IS NULL OR min_g IS NULL OR max_g = min_g THEN 0.0
                ELSE SAFE_DIVIDE(net_qty_30d - min_g, max_g - min_g)
                END AS popularity
            FROM genre_minmax
            ),
            sold_until_now AS (
            -- as_of_ts ì‹œì ê¹Œì§€ íšŒì°¨ë³„ ëˆ„ì  ìˆœíŒë§¤
            SELECT
                performance_code,
                performance_ts,
                SUM(CASE WHEN booking_cancel_type = '2'
                        THEN -COALESCE(booking_cancel_qty,0)
                        ELSE  COALESCE(booking_cancel_qty,0)
                    END) AS net_sold
            FROM clean
            WHERE booking_cancel_ts <= CAST('{day_setting}' AS TIMESTAMP)
            GROUP BY performance_code, performance_ts
            )
            SELECT
                CONCAT(
                        b.performance_code, '_',
                        FORMAT_TIMESTAMP('%Y%m%d%H%M', b.performance_ts, 'Asia/Seoul')
                    ) AS show_id,
                b.performance_code, 
                b.performance_ts, 
                b.performance_name  AS title,
                b.genre_name        AS genre,
                b.subgenre_name     AS subgenre,
                b.venue_name        AS venue,
                b.region_name       AS city,
                b.address           AS address,
                b.performance_ts    AS datetime,
                b.unit_price        AS price_avg,
                b.production_company_name AS producer,
                IFNULL(b.cast_info, '') AS cast_text,            -- â† cast ì˜ˆì•½ì–´ í˜¼ë™ ë°©ì§€
                IFNULL(ps.popularity, 0.0) AS popularity,        -- 0~1 (ë‚®ì„ìˆ˜ë¡ ë¹„ì¸ê¸°)
                CASE WHEN COALESCE(b.seats_for_sale,0) >= 1000 THEN 1 ELSE 0 END AS is_major,
                COALESCE(b.seats_for_sale, 0) AS seats_total,
                GREATEST(0, COALESCE(b.seats_for_sale,0) - COALESCE(s.net_sold,0)) AS seats_left,
                acs.accessible_seat_count as accessible_seat_count,
                url.sales_page_url as sales_page_url,
                openai.opnai_output
                FROM base b
                    LEFT JOIN popularity_scaled ps 
                        ON b.performance_code = ps.performance_code
                    LEFT JOIN sold_until_now s 
                         ON b.performance_code = s.performance_code 
                        AND b.performance_ts = s.performance_ts
                    INNER JOIN pg_snapshot.dm_openai_output openai
                         ON b.performance_code = openai.performance_code
                    LEFT JOIN  pg_snapshot.dm_accessible_seat acs
                         ON b.venue_code = acs.venue_code
                    LEFT JOIN pg_snapshot.dm_performance_interpark url
                         ON b.performance_code = url.performance_code
                         AND b.performance_ts  = PARSE_TIMESTAMP('%Y-%m-%d %H:%M', url.performance_ts, 'Asia/Seoul')
                    ORDER BY b.performance_ts
            """
        )

    sql = ('''SELECT *
          FROM pg_snapshot.temp_df_show3
          ORDER BY 1''')

    df = fn_query(sql)
    # datetime í‘œì¤€í™”(KST í‘œì‹œìš©)
    if "datetime" in df.columns:
        df["datetime"] = pd.to_datetime(df["datetime"], utc=True, errors="coerce").dt.tz_convert("Asia/Seoul")
    # ê²°ì¸¡ ë³´ì •
    for c in ["title","genre","venue","city","price_avg","opnai_output"]:
        if c in df.columns:
            df[c] = df[c].fillna("")

    return df

# --------------------------
# 4) í•„í„° ì ìš© â†’ í›„ë³´ ì¶•ì†Œ
# --------------------------
def apply_filters(df: pd.DataFrame, f: QueryFilters) -> pd.DataFrame:
    if df.empty: return df
    out = df.copy()

    # ê¸°ê°„
    if "datetime" in out.columns:
        out = out[(out["datetime"] >= f.start_date) & (out["datetime"] < f.end_date)]

    # ì§€ì—­/ì¥ë¥´/ì¥ì†Œ
    if f.city and "city" in out.columns:
        out = out[out["city"].astype(str).str.contains(re.escape(f.city), na=False)]
    if f.genre and "genre" in out.columns:
        out = out[out["genre"].astype(str).str.contains(re.escape(f.genre), na=False)]
    if f.venue and "venue" in out.columns:
        out = out[out["venue"].astype(str).str.contains(re.escape(f.venue), na=False)]

    # ì„œë¸Œë¡œì¼€ì´ì…˜: addressì— ë¶€ë¶„ì¼ì¹˜ (ì—¬ëŸ¬ ê°œë©´ OR)
    if getattr(f, "sublocs", None) and "address" in out.columns:
        pat = "|".join(re.escape(s) for s in f.sublocs if s)
        if pat:
            out = out[out["address"].astype(str).str.contains(pat, na=False)]

    # ì˜ˆì‚°
    if f.max_price and "price_avg" in out.columns:
        with np.errstate(invalid="ignore"):
            out = out[(out["price_avg"].fillna(0) <= f.max_price)]

    # ë² ë¦¬ì–´í”„ë¦¬
    if st.session_state.get("bf_only", True):
        out = out[out["accessible_seat_count"].fillna(0) > 0]

    return out.reset_index(drop=True)


# --------------------------
# 5) ì‹œë§¨í‹± ë§¤ì¹­ (BM25 â†’ ì„ë² ë”© ì¬ë­í‚¹)  â€» í•„í„°ë§ëœ ì§‘í•©ì—ë§Œ ìˆ˜í–‰
# --------------------------
EMBED_MODEL = os.getenv("EMBED_MODEL", "text-embedding-3-small")
CHAT_MODEL  = os.getenv("CHAT_MODEL", "gpt-5-mini")  

def compose_doc_text(row: pd.Series) -> str:
    return (
        f"ê³µì—°ëª…: {row.get('title','')}\n"
        f"ê³µì—°ì¥: {row.get('venue','')} ({row.get('city','')})\n"
        f"ì¥ë¥´: {row.get('genre','')}\n"
        f"ë©”íƒ€: {row.get('opnai_output','')}"
    )

def build_bm25(texts: List[str]) -> BM25Okapi:
    tokens = [tok(t.lower()) for t in texts]
    return BM25Okapi(tokens)

def embed_vec(texts: List[str]) -> np.ndarray:
    resp = openai_client.embeddings.create(model=EMBED_MODEL, input=texts, encoding_format="float")
    return np.array([d.embedding for d in resp.data], dtype=np.float32)

def hyde(query: str, enable: bool, max_chars: int = 800) -> str:
    if not enable:
        return query
    sys = "ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ê·¸ëŸ´ë“¯í•œ ê°€ìƒìš”ì•½ì„ 7~9ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±."
    usr = f"ì§ˆë¬¸: {query}\n- ê³µì—°ëª…/ì¥ë¥´/ë¶„ìœ„ê¸°/ê°ì •/ì¥ì†Œ í‚¤ì›Œë“œë¥¼ í¬í•¨"
    resp = chat_complete(CHAT_MODEL, [{"role":"system","content":sys},{"role":"user","content":usr}], temperature=0.3)
    return (resp.choices[0].message.content or "")[:max_chars]

def semantic_match(query: str, df_filt: pd.DataFrame, n_bm25: int, top_k: int, use_hyde: bool):
    if df_filt.empty:
        return [], {}, pd.DataFrame()
    docs = df_filt.apply(compose_doc_text, axis=1).tolist()
    bm25 = build_bm25(docs)
    q_tokens = [t.lower() for t in tok(query)]
    scores = bm25.get_scores(q_tokens)
    order = np.argsort(-np.asarray(scores))[:max(n_bm25, top_k)]
    cand = df_filt.iloc[order].reset_index(drop=True)

    # ì„ë² ë”© ì¬ë­í‚¹
    q_text = hyde(query, enable=use_hyde)
    q_vec = embed_vec([q_text])[0]; q_vec /= (np.linalg.norm(q_vec)+1e-9)
    c_mat = embed_vec(cand.apply(compose_doc_text, axis=1).tolist())
    c_mat /= (np.linalg.norm(c_mat, axis=1, keepdims=True)+1e-9)
    sims = c_mat @ q_vec

    # ì „ì²´ í›„ë³´ score map (performance_code -> sim)
    score_map = {}
    for i in range(len(cand)):
        code = str(cand.iloc[i].get("performance_code",""))
        score_map[code] = float(sims[i])

    top_idx = np.argsort(-sims)[:top_k]
    results = []
    for i in top_idx:
        r = cand.iloc[i]
        results.append({
            "performance_code": str(r.get("performance_code","")),
            "popularity": float(r.get("popularity", 0.0)),
            "score": float(sims[i]),
            "title": r.get("title",""),
            "genre": r.get("genre",""),
            "venue": r.get("venue",""),
            "city": r.get("city",""),
            "datetime": r.get("datetime",""),
            "price_avg": r.get("price_avg",""),
            "accessible_seat_count": r.get("accessible_seat_count",""),
            "opnai_output": r.get("opnai_output",""),
        })
    return results, score_map, cand


def inject_serendipity_slot(
    ranked: list,
    df_filt: pd.DataFrame,
    score_map: dict,
    k: int,
    slot_index: int = 3,               # 4ë²ˆì§¸ (0-based)
    pop_col: str = "popularity",       # 0~1 (ë‚®ì„ìˆ˜ë¡ ë¹„ì¸ê¸°)
    code_col: str = "performance_code",
) -> list:
    if not ranked or df_filt.empty:
        return ranked

    top = ranked[:k].copy()
    if slot_index >= len(top):
        slot_index = max(0, len(top) // 2)

    chosen = {str(it.get(code_col, "")) for it in top if isinstance(it, dict)}

    df_tmp = df_filt.copy()
    if pop_col not in df_tmp.columns:
        return top
    df_tmp[pop_col] = df_tmp[pop_col].fillna(0.0)

    # í•˜ìœ„ 20% ë¹„ì¸ê¸°
    q20 = df_tmp[pop_col].quantile(0.20)
    pool = df_tmp[(df_tmp[pop_col] <= q20) & (~df_tmp[code_col].astype(str).isin(chosen))].copy()
    if pool.empty:
        return top

    # ì‹œë§¨í‹± ì ìˆ˜ë¡œ ì •ë ¬ (ì—†ìœ¼ë©´ 0)
    pool["__s"] = pool[code_col].astype(str).map(score_map).fillna(0.0)
    pool = pool.sort_values(["__s", pop_col], ascending=[False, True])

    pick = pool.head(1)
    if pick.empty:
        return top

    picked_code = str(pick.iloc[0][code_col])

    # rankedì— ìˆëŠ” ë™ì¼ ì½”ë“œ(í›„ë³´ ì¤‘) ì°¾ì•„ ë™ì¼ í¬ë§·ìœ¼ë¡œ ì‚½ì…
    ser_item = next((it for it in ranked if str(it.get(code_col, "")) == picked_code), None)
    if ser_item is None:
        # ìµœì†Œ í•„ë“œë§Œ êµ¬ì„± (ë Œë”ëŸ¬ê°€ ì‚¬ìš©í•˜ëŠ” í‚¤ ìœ„ì£¼)
        ser_item = {
            code_col: picked_code,
            "score": float(score_map.get(picked_code, 0.0)),
            "title": pick.iloc[0].get("title", ""),
            "genre": pick.iloc[0].get("genre", ""),
            "venue": pick.iloc[0].get("venue", ""),
            "city":  pick.iloc[0].get("city", ""),
            "datetime": pick.iloc[0].get("datetime", ""),
            "price_avg": pick.iloc[0].get("price_avg", ""),
            "accessible_seat_count": pick.iloc[0].get("accessible_seat_count", ""),
            "opnai_output": pick.iloc[0].get("opnai_output", ""),
        }

    top.insert(slot_index, ser_item)
    return top[:k]


def dedup_by_code(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: 
        return df
    tmp = df.copy()
    if "datetime" in tmp.columns:
        tmp = tmp.sort_values(["performance_code", "datetime"], ascending=[True, True])
    else:
        tmp = tmp.sort_values(["performance_code"])
    return tmp.drop_duplicates(subset=["performance_code"], keep="first").reset_index(drop=True)


def dedup_ranked_by_code(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    seen = set()
    uniq = []
    for it in items:
        code = str(it.get("performance_code",""))
        if code and code not in seen:
            uniq.append(it)
            seen.add(code)
    return uniq    

# --------------------------
# 6) ì¹´ë“œ í…œí”Œë¦¿ 
# --------------------------
import json

def parse_meta(opnai_output: str) -> Dict[str, Any]:
    try:
        return json.loads(opnai_output) if opnai_output else {}
    except Exception:
        return {}

def render_card(item: Dict[str, Any], rank: int):

    meta = parse_meta(item.get("opnai_output",""))
    summary = meta.get("ìš”ì•½") or ""
    keywords = meta.get("í‚¤ì›Œë“œ") or []
    kw = " Â· ".join(keywords[:8]) if isinstance(keywords, list) else ""

    # ë‚ ì§œ ë¬¸ìì—´
    try:
        dt_val = item.get("datetime")
        if isinstance(dt_val, pd.Timestamp):
            dt_str = dt_val.strftime("%Y-%m-%d %a %H:%M")
        else:
            dt_str = str(dt_val or "")
    except Exception:
        dt_str = str(item.get("datetime",""))

    # ì•ˆì „í•œ ì •ìˆ˜ í¬ë§·í„°
    def fmt_int(x) -> str | None:
        try:
            if x is None: return None
            if isinstance(x, float) and math.isnan(x): return None
            v = int(float(str(x).replace(",", "")))  # "1,234"ë„ í—ˆìš©
            return f"{v:,}"
        except Exception:
            return None

    price_str    = fmt_int(item.get("price_avg")) or "-"
    acc_seat_str = fmt_int(item.get("accessible_seat_count")) or "-"

    # ì˜ˆë§¤ ë§í¬ (ìˆì„ ë•Œë§Œ)
    raw_url = (item.get("sales_page_url") or "").strip()
    def normalize_url(u: str) -> str | None:
        if not u: return None
        if u.startswith(("http://","https://")): return u
        if u.startswith("www."): return "https://" + u
        return "https://" + u
    url = normalize_url(raw_url)
    link_html = (
        f"<div style='margin-top:10px;'>ğŸŸï¸ <b>ì—¬ê¸°ì—ì„œ ì˜ˆë§¤í•  ìˆ˜ ìˆì–´ìš”</b> â€” "
        f"<a href='{html_escape(url)}' target='_blank' rel='noopener noreferrer'>{html_escape(url)}</a></div>"
        if url else ""
    )

    # semantic score íˆ´íŒ(ë¬¸ê³¼ í†¤) â€” ë“¤ì—¬ì“°ê¸° ì—†ëŠ” ë‹¨ì¼ ë¬¸ìì—´
    score_val = float(item.get("score", 0.0) or 0.0)
    score_help_html = (
        "<div style=\"font-size:12px;color:#64748b;display:flex;align-items:center;gap:6px;\">"
        f"<span>semantic score: {score_val:.4f}</span>"
        "<span style=\"cursor:help;border-bottom:1px dotted #94a3b8;\" "
        "title=\"ë‹¹ì‹ ì˜ ì§ˆë¬¸ê³¼ ì´ ê³µì—° ì†Œê°œê°€ ì–¼ë§ˆë‚˜ â€˜ê²°ì´ ë§ëŠ”ì§€â€™ë¥¼ 0~1ë¡œ ë‚˜íƒ€ë‚¸ ì ìˆ˜ì˜ˆìš”.\n"
        "1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì§€ê¸ˆ ì°¾ëŠ” ë¶„ìœ„ê¸°ì™€ ë” ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.\n"
        "(í‚¤ì›Œë“œê°€ ê²¹ì¹˜ëŠ”ì§€, ë¬¸ì¥ì˜ ëœ»ì´ ë‹®ì•˜ëŠ”ì§€ë„ í•¨ê»˜ ì‚´í´ë´ìš”. ê°™ì€ ì§ˆë¬¸ ì•ˆì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ë§ì¶° ë³´ì—¬ì¤ë‹ˆë‹¤.)\">"
        "â“˜ help</span></div>"
    )

    # ì•ˆì „ ì´ìŠ¤ì¼€ì´í”„
    title_html   = html_escape(str(item.get("title","")))
    genre_html   = html_escape(str(item.get("genre","")))
    venue_html   = html_escape(str(item.get("venue","")))
    city_html    = html_escape(str(item.get("city","")))
    dt_html      = html_escape(dt_str)
    summary_html = html_escape(summary) if summary else "ì´ ê³µì—°ì´ ë”± ì í•©í•´ ë³´ì…ë‹ˆë‹¤!!"
    kw_html      = html_escape(kw) if kw else ""

    st.markdown(
        f"""
<div style="border:1px solid #e5e7eb;border-radius:14px;padding:14px 16px;margin:10px 0;background:#ffffff;">
  <div style="display:flex;justify-content:space-between;align-items:center;">
    <div style="font-size:18px;font-weight:700;">#{rank} {title_html}</div>
    {score_help_html}
  </div>

  <div style="margin-top:6px;color:#111827;display:flex;flex-wrap:wrap;gap:10px;">
    <span>ğŸ­ <b>{genre_html}</b></span>
    <span>ğŸ“ {venue_html} ({city_html})</span>
    <span>ğŸ—“ï¸ {dt_html}</span>
    <span>ğŸ’° {price_str}</span>
    <span>â™¿ ì¢Œì„ {acc_seat_str}</span>
  </div>

  <div style="margin-top:10px;line-height:1.5;">
    ğŸ§  <b>ì¶”ì²œ ì´ìœ </b> â€” {summary_html}
  </div>
  {("<div style='margin-top:8px;color:#374151;'>ğŸ”‘ <b>ì´ëŸ° ëŠë‚Œì´ì—ìš”!</b> â€” " + kw_html + "</div>") if kw_html else ""}
  {link_html}
</div>
""",
        unsafe_allow_html=True
    )




# --------------------------
# 7) ë©”ì¸ ì•±
# --------------------------
def run_app():
    import base64
    from pathlib import Path

    def img_to_base64(path: str) -> str:
        p = Path(path)
        return base64.b64encode(p.read_bytes()).decode("utf-8") if p.exists() else ""

    if "chat" not in st.session_state:
        st.session_state["chat"] = []  # [{"role":"user"|"assistant","content":str,"cards":list|None}]

    # ---------------------------
    # Global CSS (one place)
    # ---------------------------
    st.markdown("""
    <style>
      /* ==== Sidebar bottom caption (sticky) ==== */
      [data-testid="stSidebar"] > div:first-child,
      section[data-testid="stSidebar"] > div {
        height: 100vh; display: flex; flex-direction: column;
      }
      .sidebar-bottom { margin-top: auto; padding: 10px 8px 16px;
                        color: rgba(49,51,63,.6); font-size: 0.8rem; }
      .sidebar-bottom hr { margin: 6px 0 8px; }

      /* ==== Hero ==== */
      .hero {
        background: linear-gradient(135deg, #fbf4f6 0%, #f4f1fb 60%, #f1eefb 100%);
        border: 1px solid rgba(0,0,0,.05);
        border-radius: 18px;
        padding: 18px 22px;
        display: flex; align-items: center; justify-content: space-between; gap: 18px;
        box-shadow: 0 6px 18px rgba(0,0,0,.06);
      }
      .hero-left { display:flex; align-items:center; gap:14px; }
      .hero-logo  { height: 64px; object-fit: contain; filter: drop-shadow(0 2px 6px rgba(0,0,0,.06)); }
      .hero-tagline { margin: 0; color:#333; opacity:.9; font-size:.95rem; }
      .pills { white-space:nowrap; }
      .pill {
        display:inline-block; padding:6px 12px; border-radius:999px;
        background: rgba(255,255,255,.75); border:1px solid rgba(0,0,0,.06);
        font-size:.85rem; color:#333; margin-left:8px; backdrop-filter: blur(4px);
      }
      @media (max-width: 900px) { .hero { flex-direction: column; align-items: flex-start; }
                                  .pills { margin-top: 8px; } }

      /* ==== Empty-state card ==== */
      .emptystate {
        border: 1px dashed rgba(0,0,0,.15);
        border-radius: 12px;
        padding: 24px 28px;
        margin: 14px 0 6px;
        text-align: center;
        background: #fafafa;
        color: rgba(60,60,67,.9);
        font-size: 0.95rem; line-height: 1.55;
      }
      .emptystate h4 { margin: 0 0 10px 0; font-weight: 700; color:#2f2f2f; }
      .emptystate ul { list-style: none; padding-left: 0; text-align: left; display: inline-block; margin:12px 0 0; }
      .emptystate li::before { content: "ğŸ’¡ "; }

      /* ==== Recommendation grid ==== */
      .grid { display:grid; grid-template-columns:repeat(auto-fill,minmax(280px,1fr)); gap:14px; }
    </style>
    """, unsafe_allow_html=True)
  
    # ---------------------------
    # Sidebar
    # ---------------------------
    st.markdown("""
    <style>
    /* ì‚¬ì´ë“œë°” ì „ì²´ë¥¼ ì„¸ë¡œ í”Œë ‰ìŠ¤ + í™”ë©´ ë†’ì´ ì±„ìš°ê¸° */
    aside[data-testid="stSidebar"] > div:first-child {
    height: 100vh;
    display: flex;
    flex-direction: column;
    }

    /* ì‚¬ì´ë“œë°” ìœ„ì ¯ ì˜ì—­: ê¸°ë³¸ íŒ¨ë”© ìœ ì§€(ì˜µì…˜) */
    aside[data-testid="stSidebar"] .sidebar-content {
    padding-right: 0;  /* í•„ìš”ì‹œ ì¡°ì • */
    }

    /* í‘¸í„°ë¥¼ ë§¨ ì•„ë˜ë¡œ ë°€ê¸° */
    aside[data-testid="stSidebar"] .sidebar-footer {
    margin-top: auto;
    padding: 12px 8px 16px;
    font-size: 12px;
    color: #6b7280;
    }
    aside[data-testid="stSidebar"] .sidebar-footer hr {
    margin: 8px 0 12px;
    border-color: #e5e7eb;
    }
    </style>
    """, unsafe_allow_html=True)

    # ------------------ ì‚¬ì´ë“œë°” ------------------
    with st.sidebar:
        st.title("ì˜µì…˜")

        # --- ìˆ¨ê¹€(ê³ ì •) ì„¤ì •: UI ì—†ì´ ê°•ì œ ì ìš© ---
        DEFAULT_TODAY_SETTING = os.getenv("TODAY_SETTING", "2024-06-30")
        TODAY_SETTING = DEFAULT_TODAY_SETTING  # í•˜ìœ„ ì½”ë“œ í˜¸í™˜ìš© ë³€ìˆ˜
        st.session_state["n_bm25"] = 80
        st.session_state["top_k"] = 5
        st.session_state["use_hyde"] = True

        # --- ì§€ì—­ ì„ íƒ ---
        st.subheader("ğŸ“ ì§€ì—­ì„ íƒ")
        cities_available = CITIES
        ALLOWED_CITIES = {"ì„œìš¸"}  # ë°ëª¨: ì„œìš¸ë§Œ

        with st.expander("ì§€ì—­ ì„ íƒ", expanded=True):
            selected_cities = []
            cols = st.columns(2)
            for i, g in enumerate(cities_available):
                is_allowed = g in ALLOWED_CITIES
                default_val = st.session_state.get(f"city_{g}", True if is_allowed else False)
                checked = cols[i % 2].checkbox(
                    g, value=default_val, key=f"city_{g}",
                    disabled=not is_allowed,
                    help=None if is_allowed else "ë°ëª¨ì—ì„œëŠ” ë¹„í™œì„±í™”ë˜ì–´ ìˆì–´ìš”."
                )
                if checked:
                    selected_cities.append(g)
        st.session_state["selected_cities"] = selected_cities

        # --- ë² ë¦¬ì–´í”„ë¦¬ ê³µì—°ì¥ í•„í„° ---
        st.subheader("â™¿ ë² ë¦¬ì–´í”„ë¦¬")
        bf_only = st.checkbox(
            " ë² ë¦¬ì–´í”„ë¦¬ ê³µì—°ì¥ë§Œ ë³´ê¸°",
            value=st.session_state.get("bf_only", False),
            help="íœ ì²´ì–´ì„/ì¥ì• ì¸ í™”ì¥ì‹¤ ë“± ì ‘ê·¼ì„± ì •ë³´ë¥¼ ê°€ì§„ ê³µì—°ì¥ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤."
        )
        st.session_state["bf_only"] = bf_only

        st.markdown(
            """
            <div class="sidebar-footer">
            <hr/>
            <div>Copyright. 2025 KOPIS ë¹…ë°ì´í„° ê³µëª¨ì „_ê°€ë³´ìKU All rights reserved.</div>
            </div>
            """,
            unsafe_allow_html=True
        )



    # ---------------------------
    # Data Loading
    # ---------------------------
    with st.spinner("ê³µì—° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        df_all = load_show_candidates(TODAY_SETTING)
    total_cnt = len(df_all) if df_all is not None else 0

    if "SUBLOC_GAZ" not in st.session_state:
        st.session_state["SUBLOC_GAZ"] = build_address_gazetteer(df_all)
    else:
        st.session_state["SUBLOC_GAZ"] = build_address_gazetteer(df_all)

    # ---------------------------
    # HERO (ë¡œê³  + íƒœê·¸ë¼ì¸ + ì§€í‘œ)
    # ---------------------------
    logo_b64 = img_to_base64("assets/CueSense.png")
    logo_html = f'<img class="hero-logo" alt="CueSense" src="data:image/png;base64,{logo_b64}"/>' if logo_b64 else ""

    st.markdown(
        f"""
        <div class="hero">
          <div class="hero-left">
            {logo_html}
            <p class="hero-tagline"> ì•Œì•„ì„œ ì±™ê²¨ì£¼ëŠ” ê³µì—°ì†Œì‹, ì„¼ìŠ¤ìˆê²Œ ë”±! íì„¼ìŠ¤ </p>
          </div>
          <div class="pills">
            <span class="pill">ê¸°ì¤€ì¼: {pd.to_datetime(TODAY_SETTING).date()}</span>
            <span class="pill">ë„ì‹œ: {", ".join(selected_cities) if selected_cities else "ì„ íƒì—†ìŒ"}</span>
            <span class="pill">ê³µì—°ìˆ˜: {total_cnt:,}</span>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

    # ---------------------------
    # Tabs
    # ---------------------------
    st.markdown("##### ")
    tab_reco, tab_help = st.tabs(["âœ¨ ì¶”ì²œ", "â“ë„ì›€ë§"])

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¤€ë¹„
    st.session_state.setdefault("chat", [])

    # ============ íƒ­: ì¶”ì²œ ============
    with tab_reco:

        st.markdown("""
        <style>
        /* 1) ì±„íŒ… ì…ë ¥ì°½: í™”ë©´ í•˜ë‹¨ ê³ ì • + ë©”ì¸ì˜ì—­ë§Œ ì°¨ì§€ */
        div[data-testid="stChatInput"]{
        position: fixed;
        z-index: 999;
        bottom: 20px;                 /* ë°”ë‹¥ì—ì„œ ë„ìš°ê¸° */
        right: 24px;                  /* ìš°ì¸¡ ì—¬ë°± */
        left: 360px;                  /* ì‚¬ì´ë“œë°” í­(ëŒ€ëµ)ë§Œí¼ ë„ìš°ê¸°: í•„ìš”ì‹œ ì¡°ì • */
        max-width: 1100px;            /* ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ìƒí•œ */
        margin: 0 auto;               /* ì¤‘ì•™ ì •ë ¬ ëŠë‚Œ */
        background: white;
        padding: 0.75rem 1rem;
        border: 1px solid #e5e7eb;
        border-radius: 12px;
        box-shadow: 0 8px 24px rgba(0,0,0,0.08);
        }

        /* 2) ë°˜ì‘í˜•: í™”ë©´ì´ ì¢ì„ ë• ì¢Œìš° ì—¬ë°±ë§Œ ë‘ê³  ê½‰ ì°¨ê²Œ */
        @media (max-width: 1100px){
        div[data-testid="stChatInput"]{
            left: 16px;
            right: 16px;
            bottom: 12px;
        }
        }

        /* 3) ë‚´ìš©ì´ chat_input ë’¤ì— ê°€ë¦¬ì§€ ì•Šë„ë¡ ë©”ì¸ ì˜ì—­ì— í•˜ë‹¨ íŒ¨ë”© ì¶”ê°€ */
        section.main, div[data-testid="stAppViewContainer"] section{
        padding-bottom: 140px; /* chat_input ë†’ì´ + ì—¬ìœ  */
        }
        </style>
        """, unsafe_allow_html=True)



        # --- ìœ í‹¸ ---
        def append_chat(role: str, content: str, cards: list | None = None):
            msg = {"role": role, "content": content}
            if cards:
                msg["cards"] = cards
            st.session_state["chat"].append(msg)

        # --- 1) íˆìŠ¤í† ë¦¬ ë Œë” ---
        for turn in st.session_state["chat"]:
            with st.chat_message("user" if turn["role"] == "user" else "assistant"):
                st.markdown(turn.get("content", ""))

                # â† ì¹´ë“œê°€ ìˆìœ¼ë©´ 'ì§ì ‘' ë Œë” (ê·¸ë¦¬ë“œ ë˜í¼ ì—†ìŒ)
                cards = turn.get("cards") if isinstance(turn, dict) else None
                if cards:
                    for i, it in enumerate(cards, 1):
                        render_card(it, i)


        # --- 2) ì…ë ¥ì°½  ---
        user_q = st.chat_input("ì˜ˆ) ì´ë²ˆ ì£¼ë§ ê°•ë‚¨ ë°ì´íŠ¸ìš© ë°”ì´ì˜¬ë¦° ê³µì—° ì¶”ì²œí•´ì¤˜")

        # --- 3) ì…ë ¥ ì²˜ë¦¬ ---
        if user_q:
            # (A) ìœ ì € ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— 'ë¨¼ì €' ì €ì¥ â†’ ë¹ˆ ìƒíƒœ ë°•ìŠ¤ ì¡°ê±´ í•´ì œ
            append_chat("user", user_q)

            # (B) ì¦‰ì‹œ í™”ë©´ì—ë„ ìœ ì € ë§í’ì„  ë…¸ì¶œ(ì´ë²ˆ í”„ë ˆì„ì—ì„œ ì²´ê°)
            with st.chat_message("user"):
                st.markdown(user_q)

            # (C) ë¡œë”© ìŠ¤í”¼ë„ˆ + ê³„ì‚°
            with st.chat_message("assistant"):
                with st.spinner("ë”± ë§ëŠ” ê³µì—°ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    intent = detect_intent(user_q)

                    if intent == "ask_name":
                        # ê²°ê³¼ ì €ì¥
                        append_chat("assistant", "ì œ ì´ë¦„ì€ **CueSence**ì…ë‹ˆë‹¤. ê³µì—° ì¶”ì²œì„ ë„ì™€ë“œë¦´ê²Œìš”!")
                    elif intent != "recommend":
                        append_chat(
                            "assistant",
                            "í˜„ì¬ëŠ” **ê³µì—° ì¶”ì²œ/ê²€ìƒ‰** ì§ˆë¬¸ì— ìµœì í™”ë˜ì–´ ìˆì–´ìš”.\n\n"
                            "ì˜ˆì‹œ) `ì´ë²ˆ ì£¼ë§ ê°•ë‚¨ ë°ì´íŠ¸ìš© ë°”ì´ì˜¬ë¦° ê³µì—° ì¶”ì²œí•´ì¤˜`, "
                            "`7ì›” ì¤‘ìˆœ í´ë˜ì‹ í˜ìŠ¤í‹°ë²Œ ê°™ì€ ëŒ€í˜• ê³µì—° ìˆì–´?`"
                        )
                    else:
                        try:
                            try:
                                base_dt = pd.to_datetime(TODAY_SETTING).to_pydatetime()
                            except Exception:
                                base_dt = dt.datetime.now()

                            filters = parse_user_query(
                                user_q, base_dt,
                                subloc_gaz=st.session_state.get("SUBLOC_GAZ", [])
                            )
                            if selected_cities:
                                try:
                                    filters.cities = selected_cities
                                except Exception:
                                    pass

                            df_filt = apply_filters(df_all, filters)
                            df_filt = dedup_by_code(df_filt)

                            if df_filt is None or df_filt.empty:
                                append_chat(
                                    "assistant",
                                    "ì¡°ê±´ì— ë§ëŠ” ê³µì—°ì´ ì—†ì–´ìš”. ê¸°ê°„/ì§€ì—­/ì¥ë¥´ë¥¼ ì¡°ê¸ˆ ë„“í˜€ë³¼ê¹Œìš”?"
                                )
                            else:
                                ranked, score_map, cand_df = semantic_match(
                                    user_q, df_filt,
                                    n_bm25=st.session_state['n_bm25'],
                                    top_k=st.session_state['top_k'],
                                    use_hyde=st.session_state['use_hyde']
                                )
                                ranked = dedup_ranked_by_code(ranked)
                                ranked = inject_serendipity_slot(
                                    ranked=ranked,
                                    df_filt=df_filt,
                                    score_map=score_map,
                                    k=st.session_state["top_k"],
                                    slot_index=3,
                                    pop_col="popularity",
                                    code_col="performance_code",
                                )

                                if ranked:
                                    append_chat("assistant", "### âœ… ì¶”ì²œ ê²°ê³¼", cards=ranked)
                                else:
                                    append_chat(
                                        "assistant",
                                        "í•„í„°ì— ë§ëŠ” ê³µì—°ì€ ìˆì—ˆì§€ë§Œ, ì‹œë§¨í‹± ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”."
                                    )
                        except Exception as e:
                            append_chat("assistant", f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")

            # (D) íˆìŠ¤í† ë¦¬ì— ì €ì¥ì´ ëë‚¬ìœ¼ë‹ˆ, ìƒˆ íˆìŠ¤í† ë¦¬ë¡œ í™”ë©´ ì „ì²´ ì¬ê·¸ë¦¬ê¸°
            st.rerun()

        # --- 4) ë¹ˆ ìƒíƒœ ë°•ìŠ¤ ---
        # chatì´ ë¹„ì–´ ìˆì„ ë•Œë§Œ ë³´ì—¬ì¤Œ (ìœ ì € ì…ë ¥ í›„ì—ëŠ” ìœ„ì—ì„œ appendë˜ì–´ ì¦‰ì‹œ ì‚¬ë¼ì§)
        if not st.session_state["chat"]:
            st.markdown(
                """
                <div class="emptystate">
                <h4>ì•„ì§ ì¶”ì²œì„ ì‹œì‘í•˜ì§€ ì•Šì•˜ì–´ìš”</h4>
                <div>ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ë¬¼ì–´ë³´ì„¸ìš”:</div>
                <ul>
                    <li>ì´ë²ˆ ì£¼ë§ ì„œìš¸ ë°ì´íŠ¸ìš© ë°”ì´ì˜¬ë¦° ê³µì—° ì¶”ì²œí•´ì¤˜</li>
                    <li>7ì›” ì¤‘ìˆœì— í´ë˜ì‹ í˜ìŠ¤í‹°ë²Œ ê°™ì€ ëŒ€í˜• ê³µì—° ìˆì–´?</li>
                </ul>
                </div>
                """,
                unsafe_allow_html=True
            )


    # ============ íƒ­: ë„ì›€ë§ ============
    with tab_help:
        st.markdown("#### ì‚¬ìš© ë°©ë²•")
        st.markdown(
            """
            - ìì—°ì–´ë¡œ ê¸°ê°„Â·ì¥ì†ŒÂ·ì¥ë¥´Â·ë¶„ìœ„ê¸°ë¥¼ í•¨ê»˜ ì ì–´ì£¼ì„¸ìš”.  
            - ì˜ˆ) *â€œì´ë²ˆ ì£¼ë§ ê°•ë‚¨ ë°ì´íŠ¸ìš© ë°”ì´ì˜¬ë¦° ê³µì—° ì¶”ì²œí•´ì¤˜â€*  
            - ë°ëª¨ì—ì„œëŠ” **ì„œìš¸ë§Œ** í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
            """
        )

        # í•˜ë‹¨ ë¡œê³  (íƒ­ ë°”ë‹¥ ê³ ì • ëŠë‚Œ)
        help_logo_b64 = img_to_base64("assets/help.png") or img_to_base64("assets/CueSense.png")
        st.markdown(f"""
        <style>
          .help-wrap {{ display:flex; flex-direction:column; min-height: 52vh; }}
          .help-footer {{ margin-top:auto; text-align:center; padding:16px 0 6px; opacity:.9; }}
          .help-footer img {{ height: 40px; filter: drop-shadow(0 1px 4px rgba(0,0,0,.07)); }}
        </style>
        <div class="help-wrap">
          <div class="help-footer">
            {"<img src='data:image/png;base64," + help_logo_b64 + "' alt='CueSense'/>" if help_logo_b64 else ""}
          </div>
        </div>
        """, unsafe_allow_html=True)



if __name__ == "__main__":
    run_app()
